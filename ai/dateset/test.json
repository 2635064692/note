[
  {
    "content": "### 重点组件类\n\n### 配置类config\n\n- WebSecurityConfigurerAdapter（安全服务器如登录，退出）\n    - 集成此接口可快速实现 Web 安全相关的配置\n    - 需要增加@EnableWebSecurity注解\n    - 包含身份验证和授权规则；用户信息源；“记住我”功能；密码加密；注销处理\n    - 有登录认证的服务需要配置，配置后不需要配置ResourceServerConfigurerAdapter\n- ResourceServerConfigurerAdapter（资源token验证配置，资源服务器配置）\n    - 非登录服务需要配置资源访问权限\n- AuthorizationServerConfigurerAdapter（oath2服务端配置，授权服务器配置）\n\n### 关键功能类\n\n- FilterChainProxy：协调所有安全过滤器，按照顺序执行过滤器，如\n    - UsernamePasswordAuthenticationFilter处理用户名密码认证流程；\n    - BasicAuthenticationFilter处理 HTTP Basic 认证流程；\n    - JwtAuthenticationTokenFilter用于处理基于 JWT 令牌的认证流程\n- TokenEndpoint：oauth2内置接口，登录实现逻辑；\n    - 注：前置filter过滤器通过后才会进入该接口。\n    - scop校验；token生成；\n- OAuth2AuthenticationProcessingFilter：处理授权码模式 授权码模式授权认证\n    - AbstractAuthenticationProcessingFilter：核心过滤器，上述filter基类，\n- ClientCredentialsTokenEndpointFilter：client验证filter，若登录时，client校验成功，则直接执行/oauth/token接口执行身份验证请求。\n- DaoAuthenticationProvider：登录账号密码校验#additionalAuthenticationChecks\n- 用户登录成功或失败后无法执行后置处理，不在filter职责范围内。\n\n### 授权码鉴权逻辑\n\n### 单点登录实现原理\n\n### antMatchers(ignore).permitAll()\n\n- 配置忽略地址，不鉴权；最终会到FilterSecurityInterceptor#invoke 验证是否存在有效的鉴权上下文信息最终 AbstractSecurityInterceptor#attemptAuthorization 校验当前接口及权限是否匹配。\n\n### 不存在接口地址，访问报401错误（应该404）\n\n- springboot框架 javax.servlet.http.HttpServlet#service具体接口访问逻辑\n- org.springframework.web.servlet.FrameworkServlet#doGet 执行get逻辑\n- 接口地址匹配实现（基本原理就是从map里面匹配url）\n    - org.springframework.web.servlet.handler.AbstractHandlerMethodMapping#lookupHandlerMethod\n    \n\n### 权限校验”不允许访问“\n\n- org.springframework.security.access.vote.AffirmativeBased#前置校验，",
    "summary": "spring security oauth2学习笔记",
    "name": "spring security oauth2",
    "url": "./sharepoint/Work from home policy.txt",
    "created_on": "2020-03-01",
    "updated_at": "2020-03-01",
    "category": "teams",
    "_run_ml_inference": true,
    "rolePermissions": [
      "demo",
      "manager"
    ]
  },
  {
    "content": "> channel：建立好的连接（通道）\nSelector：解决一个线程多个网络连接复用问题\n> \n- 线程上下文切换：根据线程的状态如RUNNING，需要申请cpu时间片，会进行线程上下文的切换；若为waiting，则不会\n\nserver启动\n\n- bossGroup绑定serverSocketChannel\n- workGroup绑定socketChannel\n\n### client连接server\n\n- 初始化socketChannel\n- javaChannel().connect(remoteAddress);\n- client socketChannel注册op_connect事件\n    - client尝试连接服务器时，会被触发\n    - 触发后会立马移除此事件的监听\n        \n        ```bash\n        ops &= ~SelectionKey.OP_CONNECT;\n        k.interestOps(ops);\n        ```\n        \n- client监听op_connect事件，完成连接后，bindRead 绑定OP_READ事件\n\nwriteAndFlush\n\n- \n\n### netty相比Java NIO优势\n\n### Java NIO、AIO、BIO\n\n- nio：同步非阻塞\n- aio：异步非阻塞\n- bio：同步阻塞\n\n### reactor模式\n\n- \n\n多路复用\n\n- 一个selector监听多个channel，后通知eventLoop，这样，一个eventLoop就能够处理多个事件\n\n跨平台\n\nnetty解决粘包 半包\n\n- 粘包：为了提高网络传输性能，多个数据包一起发送，此刻，接收方就相当于接收到一整个包\n- 半包：由于数据包过大，必须拆分传输，导致半包\n\n编解码\n\n- 支持json、xml、protobuf等\n- 解码，byte-》nettyBufer-》object\n\nkeepalive 及 idle检测\n\n- idle检测：服务端空闲一段时间（无请求访问）后，进入idle检测状态，此时会发起keepalive验证\n- keepalive：长连接，长时间空闲不工作，将会被中断\n- io.netty.handler.timeout.IdleStateHandler#观察者模式，写进度观察 initOutputChanged（有待确认）\n\nnetty锁\n\n队列（jdk LinkedBlockingQueue(mpmc多生产者多消费者模式)）→ jctools mpsc 单消费者（bossGroup只有一个线程）\n\nserver启动流程\n\n- 创建selector（控制处理channel）\n- 创建channel并绑定上selector\n- channel绑定地址启动\n- \n\nclient启动流程\n\n- 向server注册，即server接受OP_ACCEPT\n- client注册OP_READ事件处理读数据\n\nChannelOutboundHandlerAdapter 和  ChannelInboundHandlerAdapter 区别\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b3e46b3c-8c8b-45ea-9757-b57c9b89ebae/Untitled.png)\n\n- Context 包装handler执行\n- inbound 接受\n- outbound 写\n\n关闭连接\n\n- 触发op_read 读取字节-1\n\n服务关闭\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4d27f117-4104-4cc1-b4aa-f8bc2aa71ec3/Untitled.png)\n\nctx.writeAndFlush对比ctx.channel.writeAndFlush\n\n- 前者从当前上下文执行，后者从pipline起始开始执行（即从tail开始）\n- 如果你想让消息经过处理器链中的所有处理器，应使用`ctx.channel().writeAndFlush()`。如果你只想让消息经过当前处理器之前的处理器，应使用`ctx.writeAndFlush()`\n\nnetty支持的系统参数",
    "summary": "Netty学习笔记",
    "name": "Netty",
    "url": "./sharepoint/April work from home update.txt",
    "created_on": "2022-04-29",
    "updated_at": "2022-04-29",
    "category": "teams",
    "_run_ml_inference": true,
    "rolePermissions": [
      "demo",
      "manager"
    ]
  },
  {
    "content": "## 消费者\n\n### 功能点\n\n> 消息的消费方式、记录消费进度、消息的消费状态\n> \n\n- 集群、广播消费\n    - 集群消费，消费进度由broker维护，对应`org.apache.rocketmq.client.consumer.store.LocalFileOffsetStore`\n    - 广播消费，消费进度由consumer客户端自行维护，对应`org.apache.rocketmq.client.consumer.store.RemoteBrokerOffsetStore`\n- 消息推、拉模式\n    - push方式，需要注意consumer消费速率，消费太慢，可能会造成积压\n    - pull方式，不好控制拉取时间，可能某一段时间内拉取数量过大，一段时间内无消息\n- 并发消费、顺序消费\n- 消费失败重试机制\n    - 集群消息消费会重试，加入到retry topic中\n- 指定消费点位，队头、队尾、指定点位\n\n![push 消费模式](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f31376eb-89b1-4329-915d-9c82eabb57b6/Untitled.png)\n\npush 消费模式\n\n![pull 消费模式](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/11dcfa4d-885a-4c31-b582-950add27d533/Untitled.png)\n\npull 消费模式\n\n![Orderly、Concurrently 消费区别](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/65bb753a-6eb2-4e5d-bbd3-5eabeaa1b278/Untitled.png)\n\nOrderly、Concurrently 消费区别\n\n## broker\n\n### 功能点\n\n- broker侧能够配置落盘方式，（同步、异步）\n- 定时任务处理\n- 主节点负责数据读写、事务消息、延时消息处理\n- 延时消息topic维护\n\n## 生产者\n\n### 消息发送\n\n- 三种模式：oneway、sync、async；async模式发送失败，将会重试\n\n- TBW102默认topic（保证发送到broker的信息完整度），broker自动创建\n- 主节点负载超过60%，分摊压力至从节点\n- 异步请求限流处理\n- 通过指定Queue（算法），将某一业务消息发送到同一个队列，实现顺序消息\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1bd5e09b-e82f-402d-9f91-20003cddd5f3/Untitled.png)\n\n### 主从同步复制\n\n> 同步模式：异步、同步；同步数据分类：commitLog、元数据（topic、consumerOffest、group）\n> \n- 同步：master节点commitLog添加，会将数据通过socket通信方式传递从salve节点。\n- 异步：完全依靠socket通信，salve节点定时通信请求数据。\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ffbf53e9-6820-493b-b4d6-a23298b13b51/Untitled.png)\n\n![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6a74d63f-b3e9-4549-bfd1-7a016b43a141/Untitled.png)\n\n## nameServ\n\n### 接收broker注册，包含topic、group等信息\n\n## spring-stream集成rocketmq\n\n- 默认DefaultMQPushConsumer消费者\n- 默认DefaultMQProducer生产者",
    "summary": "rocketMq学习笔记",
    "name": "rocketMq",
    "url": "./sharepoint/WFH policy update May 2023.txt",
    "created_on": "2023-05-01",
    "updated_at": "2023-05-01",
    "category": "teams",
    "_run_ml_inference": true,
    "rolePermissions": [
      "demo",
      "manager"
    ]
  },
  {
    "content": "1. 使用开源模型将特定字段转换成词向量\n    \n    ```css\n    from sentence_transformers import SentenceTransformer\n    \n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n    ## 转换向量\n    book[\"title_vector\"] = model.encode(book[\"title\"]).tolist()\n    ```\n    \n2. 使用es内置ELSER转换词向量\n3. 创建同义词api\n    \n    ```python\n    synonyms_set = [{\"id\": \"synonym-1\", \"synonyms\": \"js, javascript, java script\"}]\n    \n    client.synonyms.put_synonym(id=\"my-synonyms-set\", synonyms_set=synonyms_set)\n    ```\n    \n4. 向量数据库索引\n5. 算法\n    1. k-means（聚类）（近似最近邻？）\n    2. 随机超平面\n    3. 导航小世界（NSW）\n        1. 将向量随机放入到高维空间，近邻3个点连接，先粗查，后精细\n    4. 分层导航小世界（HNSW）\n6. 超长文本将会分桶，chunk\n    1. @see [es处理超长文本向量化](https://www.elastic.co/search-labs/blog/chunking-via-ingest-pipelines)\n7. 降低存储开销\n    1. 乘积量化，原始向量用质心向量替代（可能会产生维度灾难）\n    2. \n\n### 问题\n\n1. 超长文本如何向量化\n    1. 分段：使用\r\n（注：若分段超长，可继续使用分句的方式）\n    2. 分句：自然语言工具包(NLTK)、spaCy\n    3. 滑动窗口\n2. elaticsearch中能否使用量化的方式降低存储开销\n    1. 需要外挂或者插件\n3. 搜索算法有哪些\n    1. 局部hash算法：计算hash，碰撞尽可能高，分配到同一个桶中，说明相似度较高；需要设计hash算法，不长使用\n    2. 分层导航小世界（HNSW）\n    3. knn近邻法\n    4. k-means聚类算法：涉及到边缘问题（某个点与另一个分类中的某个点更近），设计多个聚类，多搜索几个分类，缺点：将导致聚类爆炸；有损压缩（聚类中的每个点都用质心点代替），即量化\n        1. 码本，\n        2. 维度升高，码本将暴涨（维度灾难）；解决方式：将高维向量（128）拆分成低维子向量（8*16），对子空间的向量进行k-means聚类训练，子空间得到的码本数量（即质心数量，256）有限，最终，高维向量对每个子向量使用质心向量的编号（如2），最终汇总成一个8维的新向量，该新向量通过查找子空间的码表即可得到对应的质心向量\n4. 降低存储开销的方式有哪些\n    1. PQ（product Quantization）\n    2. IVF-PQ：\n5. 文本向量化，维度如何考虑\n    1. 考虑到项目实际情况以及成本，使用开源模型降维（未找到直接生成128维的词向量模型）128维的词向量进行存储（PCA）\n\n最近一个AI相关的应用是云笔记的AI处理相关功能，包括笔记内容的搜索（主要使用的是RAG技术点），针对笔记内容进行交互式问答对话（其实也是一个增强搜索然后通过LangChain让通用模型进行总结汇总），基于当前笔记内容续写后续内容（纯模型训练相关），以及其他相关的ORC、翻译、摘要等ai相关的子功能（三方模型包）。\n\nRAG相关技术主要使用的Elaticsearch作为向量数据库，使用HNSW作为搜索算法（后续有计划使用PQ量化技术降低内存占用。）（k-means + HNSW 结合，新增数据使用HNSW搜索算法，训练并且量化后的数据使用k-means？）\n\nHNSW算法问题\n\n- 不支持删除，标记删除节点，搜索直接忽略\n- 返回不足K个问题，修改ef_search 参数，控制在图中探索的候选节点数量\n\n什么时候需要微调，什么时候需要使用RAG\n\n对笔记内容进行向量化存储\n\n混合查询，标题匹配，内容使用向量搜索（k-means）",
    "summary": "elaticsearch向量数据库学习笔记",
    "name": "elaticsearch向量数据库",
    "url": "./sharepoint/FY2024 Company Sales Strategy.txt",
    "category": "teams",
    "created_on": "2023-04-15",
    "updated_at": "2023-04-15",
    "_run_ml_inference": true,
    "rolePermissions": [
      "demo",
      "manager"
    ]
  },
  {
    "content": "### 内省机制\n\n- POJO属性变化监听\n\n```java\n\n    /**\n     * 属性（生效）变化监听器管理器\n     */\n    private PropertyChangeSupport propertyChangeSupport = new PropertyChangeSupport(this);\n\n    /**\n     * 属性（否决）变化监听器\n     */\n    private VetoableChangeSupport vetoableChangeSupport = new VetoableChangeSupport(this);\n\n```\n\n### java编译期和运行期\n\n- 编译期：将.java文件编译成class文件的过程，\n- 运行期：jvm加载class字节码文件、使用、卸载的过程\n\n### java泛型类型擦除\n\n> 和List<String>等类型，在编译后都会变成List即原始类型（擦除泛型后的类型）\nfastjson中使用TypeReference来解决泛型类型擦除问题。\n> \n\n### 校验字符串所占字节\n\n```\npublic static void main(String[] args) {\n    String s = \"犯得上发11\";\n    byte[] msg = s.getBytes(StandardCharsets.US_ASCII);\n\n    ByteBuf buf = Unpooled.wrappedBuffer(msg);\n    int i = buf.readableBytes();\n}\n\n```\n\n### 中文字符在不同编码集中所占字节不一样 (E英文字符 C中文字符包含繁体 Ef = 英文符号 Cf=中文符号)\n\n- StandardCharsets.US_ASCII ASCII E=1 C=2 测试中文有问题 只占一个字节\n- StandardCharsets.UTF_8 UTF_8 E=1 C=3\n- StandardCharsets.UTF-16 UTF-16 E=2 C=2 扩展区的汉字站4字节\n- [StandardCharsets.xxx](http://standardcharsets.xxx/) Unicode E=2 C=2 Ef=1 Cf=2\n- GBK E=1 C=2\n\n### 分布式事务\n\n> B->C 顺序执行，C执行失败，A,B补偿回滚，手动增加或者减少数据库数据\n> \n- 拆分单个数据库事务\n- 补偿机制\n\n### 字符串为什么被设计成final\n\n> 前言\n数据结构存在堆里\n数据引用在栈中\n> \n\n> 字符串为什么被设计成final\n> \n\n> 示例\n> \n\n### Date处理\n\n> date、datetime、timestamp区别\n> \n- date 数据库 存储 年月日\n- datetime 数据库存储 年月日 时分秒 默认时分秒为 00:00:00 并未存储时区信息\n- timestamp 数据库存储 年月日 时分秒 默认 时分秒 00:00:00 同时还存储时区信息\n- 使用注解可将入参格式化\n\n```\n@JsonFormat(\n            pattern = \"yyyy-MM-dd\"\n    )\n\n```\n\n!https://secure2.wostatic.cn/static/dcaJGnv9GESf1kVFQgaGNV/image.png?auth_key=1705236572-qbwQ7SxdQZfPCycZbY7p1e-0-9b45ad6218d5ee6665b6a8b278ed6755\n\n### hashCode的含义\n\n> 通过hashcode在内存堆中查找到相应的对象\n> \n- HashCode的存在主要是为了查找的快捷性，HashCode是用来在散列存储结构中确定对象的存储地址的\n- 如果两个对象equals相等，那么这两个对象的HashCode一定也相同\n- 如果对象的equals方法被重写，那么对象的HashCode方法也尽量重写\n- 如果两个对象的HashCode相同，不代表两个对象就相同，只能说明这两个对象在散列存储结构中，存放于同一个位置\n\n> 重写equals不重写hashCode的隐患\n> \n- 先通过hashCode判断该存储位置是否\n\n### 获取springboot resource下文件信息\n\n```\nClassPathResource classPathResource = new ClassPathResource(\"static/apiclient_cert.p12\");\n                    InputStream certStream =classPathResource.getInputStream();\n\n```\n\n### javafx.util.Pair 的使用\n\n```\nList<Pair<String, String>>  list1=new ArrayList();\nlist1.add(new Pair<>(\"a\",\"d\"));\n\n类似 于List<Pair> 类似于map\n若要对 map value 值进行排序\n\npair 可以如下操作\n\nCollections.sort(topList, new Comparator<Pair<Integer, JSONObject>>() {\n            @Override\n            public int compare(Pair<Integer, JSONObject> o1, Pair<Integer, JSONObject> o2) {\n                //这里想使用JSONObject的值来进行排序\n                return o2.getValue().getIntValue(\"a\") - o1.getValue().getIntValue(\"a\");\n            }\n        });\n\n```\n\n### 偏移量运算\n\n> \n> \n- 若为正数，高位补0\n- 若为负数，高位补1\n\n!https://secure2.wostatic.cn/static/k78JBu3pyhqEaBvmpqCKiR/image.png?auth_key=1705236572-ndobrHkqeJAPdiEduuU2Tm-0-bf9c3a6dc70d7ae3172f4cf7f2b40954\n\n> 左移<<\n> \n- 低位补0不分正负数\n\n!https://secure2.wostatic.cn/static/k41W82QHyV3MJ5kYhfPEGQ/image.png?auth_key=1705236572-m3PmJ25tPs2LfFSznh6Uzk-0-089c31e8d5bf5c8d94f38a8fdcf06d1d\n\n> \n> \n- 也叫逻辑右移，即若该数为正，则高位补0，而若该数为负数，则右移后高位同样补0\n\n### 二进制 与、或、异或运算\n\n- 与&：同1为1，0&0=0 0&1=0 1&1=1\n- 或|：有1为1，0|0=0 0|1=1 1|1=1\n- 异或^：不同为1，0^0=0 0^1=1 1^1=0\n\n### 跳过类型擦除机制TypeReference使用\n\n> 问题引出：\n> \n\n> 一公用字符串转换对象方法如下，当其真正使用时，字符串将会被转换成JsonObject类型，而不是我们期望的目标类型。\n> \n\n!https://secure2.wostatic.cn/static/qodDAgW7WeQdatUk5sCTK1/image.png?auth_key=1705236572-roXEvaDBYNiQ6opLSsQiuP-0-d37ffe300461f13fe0ab76606b1ef63e\n\n> TypeReference机制\n> \n- 初始化创建TypeReference将会先执行static LIST_STRING字段，创建默认List<String>类型的TypeReference并缓存。\n- 初始化TypeReference实际上是创建一个匿名内部类子类即\n\n```\nnew TypeReference<List<String>>(){} ==> 等同于\nclass A extends TypeReference<List<String>>{}\nnew A()\n\n```\n\n- 自理解为类型转换存储的一个媒介。即将目标的转换类型存储，在运行期使用。\n\n### 线程池(pre)\n\n- 线程池参数设置，（根据评价QPS，峰值QPS）\n\n### B-树（B-树、B+树、B*树）（pre）\n\n### tries树（前缀树、字典树）\n\n- 根节点不包含字符，除根节点外每一个节点都只包含一个字符。\n- 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。\n- 每个节点的所有子节点包含的字符都不相同。\n\n### 差值存储，有效节省存储空间\n\n> 递增数据列表，依次存储相邻数据差值，转换二进制存储。若数据过大位数过多，此时通过差值，可有效减少存储位数。\n> \n- 比如要存储如下整数：16386，16387，16388，16389，采用差值存储如下\n\n!https://secure2.wostatic.cn/static/nVsYPrVSS9L6CkawonUTCp/image.png?auth_key=1705236572-bW6nbv4mtDGktB6GvNDYww-0-28eddbccc57b7329b5f78ba1b5693513\n\n### mvc请求流程及线程池大小\n\n### ThreadLocal（同一线程数据是否共享）\n\n### org.joda.time.DateTime序列化问题\n\n> 使用dateTime进行网络传输序列化时，会报错，需要自定义格式转换输出\n自定义JsonSerializer 类继承JsonSerializer。先格式化dateTime后输出\n> \n\n```\npublic class JsonDateSerializer extends JsonSerializer<DateTime> {\n\n    @Override\n    public void serialize(DateTime date, JsonGenerator gen, SerializerProvider provider)\n            throws IOException, JsonProcessingException {\n        String string = date.toString(RtConstant.C_FORMAT_FORMATTER);\n\n        gen.writeString(string);\n    }\n}\n\n```\n\n### Spring中定义bean在使用时都初始化新的实例\n\n> 使用场景：有状态服务，该bean内部有字段属性，同一线程内部会被更改。这时如果另一线程需要获取该bean，目的是为了获取一个全新初始化无内容的bean\n> \n\n> 使用\n> \n\n```\n@Scope(value=ConfigurableBeanFactory.SCOPE_PROPTOTYPE)\n定义该bean scop为原型模式\n\n```\n\n> volatile关键字\n> \n- volatile关键字的一个重要作用是禁止指令重排序，可以使用volatile关键字修饰变量来解决无序写入产生的问题\n\n---\n\n**HashMap**\n\n### HashMap实现Cloneable接口的目的\n\n> 扰动函数\n> \n\n```\nString a = \"abc\";\nint hashCode = a.hashCode()\n(hashCode ^ (hashCode>>>16))& (size-1)\n\n```\n\n- 目的：增加随机性，让数据元素更加均衡的散列，减少碰撞。\n\n!https://secure2.wostatic.cn/static/eG7kz45pfD2YfZiCjs5MnX/image.png?auth_key=1705236572-eCMbcAqNCqUhQakTTaRBM3-0-87bcb7025e6ee210deceb9d95a339fe5\n\n> 为什么扩容需要2的倍数\n> \n- 扰动函数进行计算时，会用到数组长度-1，为2的倍数时，就会得到01111类似二进制进行与操作。\n\n> 哈希冲突的解决方案\n> \n- 链表，红黑树结构\n- 发生hash碰撞时，向后+1寻找空地址（开放寻址）\n\n> 链表转换红黑树\n> \n\n!https://secure2.wostatic.cn/static/sd6oTEsAU3NkQ6Cj5b4Yww/image.png?auth_key=1705236573-8dV8BhWSMam65iuLVMTkjw-0-1296c6acd7046ba5e8ed7505d13547ec\n\n- 链表树化条件：链表长度大于8，桶容量大于64，否则只是扩容\n- 红黑树转换成链表：当红黑树元素小于6，转换链表\n\n> 为什么不一直使用红黑树？既然红黑树结构要比链表优？？\n> \n- 红黑树查找性能高效，但是删除添加操作会破坏其平衡性，需要重新调整红黑树结构。\n\n---\n\n**JDK**\n\n### Jdk动态代理\n\n> 要求：被代理类必须是接口（因为生成的代理类需要先继承Proxy类，再实现被代理接口）\n原理：实现被代理接口，生成代理类class文件缓存在jvm中\n可以通过如下代码将jvm代理类输出文件\n> \n\n```\nbyte[] classFile = ProxyGenerator.generateProxyClass(\"$Proxy0\", Student.class.getInterfaces());\n        String path = \"G:/javacode/javase/Test/bin/proxy/StuProxy.class\";\n        try(FileOutputStream fos = new FileOutputStream(path)) {\n            fos.write(classFile);\n            fos.flush();\n            System.out.println(\"代理类class文件写入成功\");\n        } catch (Exception e) {\n           System.out.println(\"写文件错误\");\n        }\n\n```\n\n---\n\n**ArrayList**\n\n> 原理：内部构造由一个Object数组维护，添加元素add时，没有做同步处理，导致线程不安全\n> \n\n> foreach：由于存在如下判断，当使用foreach时，原list元素改变，将会抛出异常（ConcurrentModificationException：并发修改异常）\n> \n\n> ArrayList和LinkArrayList对比\n> \n\n!https://secure2.wostatic.cn/static/gmqJmc1E3a76qt3tUu77E5/image.png?auth_key=1705236573-sxej8uLxZkZdKpMhcDDqED-0-61e65b2f7bf8d8e82e9687afa4cbe3d1\n\n- 尾插：前者首先判断是否需要扩容，不需要扩容直接添加到末尾；后者需要创建node节点然后连接last节点。数据量大，前者效率高\n- 头插：前者先判断是否需要扩容，然后拷贝数组，赋值头节点；后者同上，耗时主要在创建节点对象上。数据量大，后者效率高\n- 中间插：前者同头插，时间复杂度为O(1)，耗时在数据迁移和扩容；后者需要便利查找到数据添加节点，时间复杂度为O(n)，耗时在遍历查询和对象创建上。\n\n### String中的HashCode采用31做hash值的参数\n\n> 能够减少hash碰撞的概率，容易被jvm解析识别（因为是2^5-1？）\n> \n\n### transient关键字作用\n\n> transient译为短暂的，当类被标明可序列化时，被此关键字修饰的字段将不在序列化范围内。\n> \n\n### volatile关键字\n\n> 原子性含义：\n> \n- 原子性操作就是**一个或某几个操作只能在一个线程执行完之后，另一个线程才能开始执行该操作**，也就是说这些操作是**不可分割的**，线程不能在这些操作上交替执行。\n- 如加锁执行，线程A执行完后才能允许下一线程继续执行\n\n> 可见性（即各线程之间可以共享变量，不会有线程不安全问题）\n> \n- 正常情况：变量定义或更改后，会现在cup缓存中，何时刷新到主存不确定，若再多核cup中执行操作，不同线程可能在不同cpu上执行，导致Acpu变量信息还在cpu缓存中，还未被刷新到主存，此时B线程将不能读取变量信息\n- 使用volatile关键字修饰：将不会缓存至cpu缓存，直接刷新到主存\n- 使用synchronized和Lock关键字也是此作用，即在释放锁之前，将变量信息刷新到主存。\n\n> 有序性（防止指令重排）\n> \n- 会在生成的jvm指令中插入内存屏障防止指令重排\n- 一切非原子性的操作都有可能发生指令重排\n- volatile只能保证可见性，不能保证原子性\n- volatile防止指令重排，也就是防止jvm优化执行顺序，在执行效率上可能会降低\n\n### log日志使用占位符的好处\n\n> 好处如下，方法调用将会先计算方法参数值，在调用该方法，而使用占位符，则仅仅将参数压栈操作。不会多余计算。\n> \n\n!https://secure2.wostatic.cn/static/wueCuxRH9J168EFQc5nrCM/image.png?auth_key=1705236573-9aiJ6i4xP4V2rp9wndH6UX-0-3e3daa6f3832b40b3e6ba3d216d49cf4\n\n### synchronized原理\n\n!https://secure2.wostatic.cn/static/r9fgM9jt6GygW3YweSn8NE/image.png?auth_key=1705236573-5x7M8FJSSgGBtaC2Fc5EvH-0-c8b79f0b3a69b23a52e22f058de8aa8a\n\n### springBoot 获取resources下文件问题\n\n- 如下方式在ide和jar包种都能获取\n\n```\nClassPathResource classPathResource = new ClassPathResource(\"py/BaoStockRequest.py\");\n\nInputStream inputStream = classPathResource.getInputStream();\n\n```\n\n- 如下方式在ide中能够获取，jar包运行获取为空（不确定是否是因为连接符/的问题，或直接给换成py/BaoStockRequest.py是否可行？）\n\n```\nBaoStockFeign.class.getClassLoader().getResourceAsStream(\"py\" + separator + \"BaoStockRequest.py\")\n\n```\n\n### Java中ScheduledExecutorService的使用\n\n- schedule：延迟执行\n- scheduleAtFixedRate：延迟并定时执行。\n- String内部有很多方法都是直接调用本地操作系统的api，不能被继承修改，如果这种final设计的类能够被继承并且修改原调用本地操作系统的api，将会造成安全隐患，如重写方法向操作系统内部写入恶意代码，使得安全性大大降低\n- 效率和安全\n- 堆中分配内存不会被改变，栈指向堆可重复利用\n- 不能被继承，不会被修改如( length方法 )\n- final修饰的字符串是不可变的，所以在创建字符串的时候，相应的hashCode将被缓存，不需要重新计算。此时，如果将字符串作为Map中的key，将能大大提高处理速度。\n",
    "summary": "Java学习笔记",
    "name": "Java",
    "url": "https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/ES6rw9bKZxVBobG1WUoJpikBF9Bhx1pw_GvJWbsg-Z_HNA?e=faSHVt",
    "created_on": "2018-04-15",
    "updated_at": "2018-04-16",
    "category": "sharepoint",
    "_run_ml_inference": true,
    "rolePermissions": [
      "demo",
      "manager"
    ]
  }
]